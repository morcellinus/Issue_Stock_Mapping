{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ë¶ˆìš©ì–´ì œê±°+TFIDF.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pb8e5uYonnbO","executionInfo":{"status":"ok","timestamp":1635772395705,"user_tz":-540,"elapsed":23834,"user":{"displayName":"Jinmo Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3uyHOWoO8CsikkBRRUhBw5GNVpf7sVI49Lads=s64","userId":"05361241896227181689"}},"outputId":"1758665f-4c54-49ea-9a16-4d0f6c430574"},"source":["! pip install konlpy\n","import konlpy\n","from konlpy.tag import Kkma\n","from konlpy.utils import pprint\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.4 MB 1.3 MB/s \n","\u001b[?25hCollecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 86 kB 4.6 MB/s \n","\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 448 kB 38.5 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n","Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"SF3x6XtZAU8P"},"source":["# ë¶ˆìš©ì–´ ì‚¬ì „ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n","#########################################\n","# ìì‹ ì´ ë§¡ì€ ì„¹ì…˜ì— ë§ëŠ” ì‚¬ì „ ê°€ì ¸ì˜¤ê¸°!! #\n","# ex) IT&ê¸°ìˆ ì´ë©´ stopword_IT&ê¸°ìˆ _okt.csv #\n","########################################\n","\n","stopword = pd.read_csv('/content/drive/Shareddrives/ğŸ¥‘PSAT_DM_2728ğŸ¥‘/Dataset/á„‡á…®á†¯á„‹á…­á†¼á„‹á…¥á„†á…©á„‹á…³á†·/stopword_á„€á…§á†¼á„Œá…¦&á„‰á…¡á„’á…¬_okt.csv', encoding = 'utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"00_YI7ptQ60L"},"source":["# ë¶ˆìš©ì–´ë¥¼ ì‚­ì œí•  ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°(íŒŒì¼ ì´ë¦„ì´ token_kkma_oktë¡œ ëë‚˜ì•¼ê² ì£ ?)\n","## ë§ˆì°¬ê°€ì§€ë¡œ ë°ì´í„° í™•ì¸ ì˜ í•˜ì„¸ìš” ##\n","\n","data = pd.read_csv('/content/drive/Shareddrives/ğŸ¥‘PSAT_DM_2728ğŸ¥‘/Dataset/á„€á…µá„‰á…¡á„á…³á„…á…©á†¯á„…á…µá†¼_á„á…©á„á…³á†«á„’á…ª_okt/á„€á…§á†¼á„Œá…¦&á„‰á…¡á„’á…¬_20211022_token_kkma_okt.csv', encoding = 'utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"icc0II7DSQQG"},"source":["# ë°ì´í„°í”„ë ˆì„ì˜ 'token_okt' ì¹¼ëŸ¼ì´ í•˜ë‚˜ì˜ ìŠ¤íŠ¸ë§ìœ¼ë¡œ ì—°ê²°ëœ í˜•íƒœë¼ì„œ ì´ë¥¼ ë–¼ì–´ì£¼ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. ì•ìœ¼ë¡œ ë°ì´í„° ì“¸ ë•Œ ë§¤ë²ˆ ì‚¬ìš©í•˜ê²Œ ë  ì˜ˆì •\n","\n","data['token_okt'] = data['token_okt'].apply(lambda k: eval(''.join(k)))\n","\n","# ë¶ˆìš©ì–´ ì‚¬ì „ì˜ ê° ì¹¼ëŸ¼ì„ ê°ê°ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë¶„í• \n","stop_words = stopword['stopword']\n","tags = stopword['tag']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7A7YJno0pCGi"},"source":["# í† í°í™” ëœ ë³¸ë¬¸ì´ (word, tag)ì˜ ê¼´ì¸ ê²ƒì„ ë– ì˜¬ë ¤ë´…ì‹œë‹¤.\n","# í•„ìš”í•œ ë‹¨ì–´ë§Œ ë‚¨ê¸°ë ¤ë©´ ë³¸ë¬¸ì˜ wordëŠ” ë¶ˆìš©ì–´ ì‚¬ì „ì— ìˆìœ¼ë©´ ì•ˆë˜ê³ , tagëŠ” ìš°ë¦¬ê°€ ì›í•˜ëŠ” tagë§Œ ë‚¨ì•„ìˆì–´ì•¼ê² ì£ ?\n","cleans = []\n","for i in range(len(data)):\n","    clean_words = [] \n","    sentence = data['token_okt'][i]\n","    for word, pos in sentence:\n","      if word not in list(stop_words) and pos in ('Noun', 'Verb', 'Adjective', 'Determiner', 'Adverb', 'Alpha', 'Unknown'):\n","        clean_words.append(word)\n","    cleans.append(clean_words)\n","\n","# ìœ„ ì‘ì—…ì„ ê±°ì¹œ í•„ìš”í•œ ë‹¨ì–´ë“¤ì„ ìƒˆë¡œìš´ ì¹¼ëŸ¼ì— 'word'ë§Œ ì €ì¥ ('word'ë§Œ ì €ì¥í•˜ëŠ” ì´ìœ ëŠ” í† í”½ëª¨ë¸ë§ì—ì„œ ê·¸ë ‡ê²Œ ì¨ì•¼í•˜ê¸° ë•Œë¬¸ì—)\n","data['clean_words'] = cleans"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cK6yGxdPrLFl"},"source":["# í•„ìš”í•œ 'word'ë§Œ ë‚¨ê¸´ ì¹¼ëŸ¼ì˜ ê° rowë¥¼ ë¬¸ì¥ì²˜ëŸ¼ ë°”ê¿”ì£¼ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.\n","doclist = []\n","for i in range(len(data)):\n","  nouns = ' '.join(data['clean_words'][i])\n","  doclist.append(nouns)\n","\n","# ì—­ì‹œ ìˆ˜í–‰ ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ ì¹¼ëŸ¼ì— ì €ì¥\n","data['clean_as_sentence'] = doclist\n","\n","########################################\n","# ì—¬ê¸°ê¹Œì§€ê°€ ë¶ˆìš©ì–´ ì œê±° ë° Tf-IDF ìš©ìœ¼ë¡œ ë³€í™˜ #\n","######################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z6hbELe8sOa3"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","tfidf_vectorizer = TfidfVectorizer(max_features = 1000)\n","x = tfidf_vectorizer.fit(data.clean_as_sentence)\n","tfidf_df = pd.DataFrame(x.transform(data.clean_as_sentence).toarray(), columns = sorted(tfidf_vectorizer.vocabulary_))\n","\n","important_words = []\n","for i in range(0, len(tfidf_df)):\n","  a = []\n","  imp_word = tfidf_df.iloc[i, :].index[tfidf_df.iloc[i, :].values > 0.05]\n","  a.append(imp_word)\n","  important_words.append(a)\n","\n","data['important_words'] = important_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WS3D7xCU61yy"},"source":["# ì´ë¦„ ë°”ê¿”ì„œ ì €ì¥í•˜ì„¸ìš”!!\n","\n","data.to_csv('/content/drive/Shareddrives/ğŸ¥‘PSAT_DM_2728ğŸ¥‘/Dataset/á„€á…µá„‰á…¡á„á…³á„…á…©á†¯á„…á…µá†¼_TFIDF/ê²½ì œ&ì‚¬íšŒ_20211022_TFIDF.csv', index = False, encoding = 'utf-8')"],"execution_count":null,"outputs":[]}]}